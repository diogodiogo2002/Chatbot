
# ğŸ“š RAG Chatbot com LangChain, FastAPI e Widget Web

Este projeto Ã© um **chatbot com RAG (Retrieval-Augmented Generation)** que responde a perguntas baseando-se em documentos PDF carregados. O sistema utiliza **LangChain**, **ChromaDB**, **FastAPI** no backend, e um **widget simples em HTML/CSS/JS** no frontend.

---

## ğŸ§  Tecnologias Utilizadas

- **FastAPI** â€” API moderna e rÃ¡pida para backend
- **LangChain** â€” Framework para RAG (RecuperaÃ§Ã£o + GeraÃ§Ã£o)
- **ChromaDB** â€” Base vetorial local para recuperaÃ§Ã£o semÃ¢ntica
- **HuggingFace Transformers** â€” Modelo de embeddings
- **Together.ai API** â€” LLM Mistral-7B-Instruct para respostas
- **HTML/CSS/JavaScript** â€” Interface do widget

---

## ğŸ“ Estrutura do Projeto

```
.
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ ingest.py               # IndexaÃ§Ã£o de documentos PDF
â”‚   â”œâ”€â”€ main.py                 # Backend FastAPI com RAG
â”‚   â””â”€â”€ chroma_db/              # Base de dados vetorial persistente
â”œâ”€â”€ docs/                       # PDF(s) a serem carregados
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html              # Interface do widget
â”‚   â”œâ”€â”€ style.css               # Estilos visuais
â”‚   â””â”€â”€ script.js               # LÃ³gica do frontend
â”œâ”€â”€ .env                        # Chave TOGETHER_API_KEY
â”œâ”€â”€ README.md                   # Este ficheiro
```

---

## âš™ï¸ InstalaÃ§Ã£o

### 1. Instalar dependÃªncias

```bash
pip install -r requirements.txt
```

**Exemplo de `requirements.txt`:**
```
fastapi
uvicorn
python-dotenv
langchain
langchain-community
langchain-chroma
sentence-transformers
together
```

### 2. Criar o ficheiro `.env`

Cria um ficheiro `.env` com a tua chave da API:

```
TOGETHER_API_KEY=sk-xxxxx
```

### 3. Colocar os PDFs

Coloca os teus documentos PDF dentro da pasta `docs/`.

### 4. Indexar os documentos

```bash
python backend/ingest.py
```

### 5. Iniciar o backend

```bash
uvicorn backend.main:app --reload
```

---

## ğŸ’¬ Como Funciona

### Passo 1: IngestÃ£o

O script `ingest.py`:
- LÃª todos os PDFs da pasta `docs/`
- Divide os documentos em pequenos trechos (chunks)
- Cria embeddings com o modelo `sentence-transformers/all-MiniLM-L6-v2`
- Armazena os embeddings na base vetorial local (`chroma_db/`)

### Passo 2: Chat

Quando o utilizador envia uma pergunta:
1. A API recebe a mensagem via `POST /chat`
2. Os `top 5` trechos mais relevantes sÃ£o recuperados da base vetorial
3. Um prompt RAG Ã© construÃ­do com os trechos e a pergunta
4. O modelo `Mistral-7B-Instruct` da Together API responde com base no conteÃºdo
5. A resposta Ã© enviada de volta ao frontend

---

## ğŸ§‘â€ğŸ’» Frontend

O `index.html` contÃ©m um widget com:
- Um botÃ£o flutuante ğŸ’¬
- Um formulÃ¡rio de envio de mensagens
- Um script JS (`script.js`) que comunica com o backend

âš ï¸ **O widget comunica com `http://127.0.0.1:8000/chat` â€” garante que o backend estÃ¡ ativo.**

---

## ğŸ›¡ï¸ SeguranÃ§a e ProduÃ§Ã£o

- Limita `CORS` a domÃ­nios especÃ­ficos em produÃ§Ã£o
- Usa autenticaÃ§Ã£o para proteger endpoints
- Encripta o `.env` e nunca o faz `commit` pÃºblico

---

## âœ… Exemplo de uso

```bash
# 1. Coloca o PDF em /docs
# 2. Corre ingest.py para criar os embeddings
# 3. Arranca o backend FastAPI
# 4. Abre index.html no navegador
# 5. Escreve uma pergunta sobre o conteÃºdo do PDF
```

---

## ğŸ§¾ LicenÃ§a

MIT â€” Sente-te Ã  vontade para modificar e usar.

---

## âœ¨ Feito por

Rodrigo GonÃ§alves e equipa ğŸš€
